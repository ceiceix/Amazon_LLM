{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1df56caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from surprise import Dataset, Reader\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise import accuracy\n",
    "from surprise import AlgoBase\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import torch\n",
    "from sentence_transformers import util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9bf4f10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Book Data\n",
    "\n",
    "book_df = pd.read_csv('Amazon_Books_Scraping/Books_df.csv')\n",
    "\n",
    "# Optionally, create a 'book_id' column if you haven't:\n",
    "if 'book_id' not in book_df.columns:\n",
    "    book_df.insert(0, 'book_id', range(len(book_df)))\n",
    "\n",
    "# We'll focus on the columns we need\n",
    "# (You can include more text in \"text_for_embedding\" if desired.)\n",
    "def create_metadata_text(row):\n",
    "    return (\n",
    "        f\"Title: {row['Title']} | \"\n",
    "        f\"Author: {row['Author']} | \"\n",
    "        f\"Main Genre: {row['Main Genre']} | \"\n",
    "        f\"Sub Genre: {row['Sub Genre']}\"\n",
    "    )\n",
    "\n",
    "book_df['text_for_embedding'] = book_df.apply(create_metadata_text, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "295e43d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare a Ratings DataFrame for Surprise\n",
    "\n",
    "ratings_df = pd.DataFrame({\n",
    "    'user_id': 0,\n",
    "    'item_id': book_df['book_id'],\n",
    "    'rating': book_df['Rating']\n",
    "})\n",
    "\n",
    "# Convert Rating to float (if it's not already)\n",
    "ratings_df['rating'] = ratings_df['rating'].astype(float)\n",
    "\n",
    "# Prepare data for Surprise\n",
    "reader = Reader(rating_scale=(1, 5))  # If your ratings are between 1 and 5\n",
    "data = Dataset.load_from_df(ratings_df[['user_id', 'item_id', 'rating']], reader)\n",
    "trainset, testset = train_test_split(data, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ad029ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Embeddings for Each Book\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "book_texts = book_df['text_for_embedding'].tolist()\n",
    "embeddings = model.encode(book_texts, convert_to_tensor=True)\n",
    "\n",
    "# We'll store them in a dictionary: book_id -> embedding\n",
    "book_embeddings = {}\n",
    "for i, row in book_df.iterrows():\n",
    "    b_id = row['book_id']\n",
    "    book_embeddings[b_id] = embeddings[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e6538c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingBased(AlgoBase):\n",
    "    def __init__(self, book_embeddings, k=10, verbose=False):\n",
    "        AlgoBase.__init__(self)\n",
    "        self.book_embeddings = book_embeddings\n",
    "        self.k = k\n",
    "        self.verbose = verbose\n",
    "    \n",
    "    def fit(self, trainset):\n",
    "        AlgoBase.fit(self, trainset)\n",
    "        return self\n",
    "    \n",
    "    def estimate(self, u, i):\n",
    "        # Try mapping internal user/item IDs to raw IDs\n",
    "        try:\n",
    "            user_id = self.trainset.to_raw_uid(u)\n",
    "        except ValueError:\n",
    "            # Unknown user\n",
    "            return self.trainset.global_mean\n",
    "\n",
    "        try:\n",
    "            item_id = self.trainset.to_raw_iid(i)\n",
    "        except ValueError:\n",
    "            # Unknown item\n",
    "            return self.trainset.global_mean\n",
    "        \n",
    "        # If the item isn't in our embedding dictionary, fallback\n",
    "        if item_id not in self.book_embeddings:\n",
    "            return self.trainset.global_mean\n",
    "\n",
    "        # Proceed with embedding-based logic\n",
    "        user_ratings = self.trainset.ur[u]  # items user has rated in the training set\n",
    "        if len(user_ratings) == 0:\n",
    "            # If user never rated anything, fallback to global mean\n",
    "            return self.trainset.global_mean\n",
    "        \n",
    "        target_emb = self.book_embeddings[item_id]\n",
    "        \n",
    "        scores_sims = []\n",
    "        for (j_inner, r_j) in user_ratings:\n",
    "            # j_inner is the internal item ID\n",
    "            j_raw = self.trainset.to_raw_iid(j_inner)\n",
    "            if j_raw not in self.book_embeddings:\n",
    "                continue\n",
    "            j_emb = self.book_embeddings[j_raw]\n",
    "            \n",
    "            # compute cosine similarity (assuming they're Torch tensors)\n",
    "            sim_val = float(util.cos_sim(target_emb, j_emb)[0][0])\n",
    "            scores_sims.append((r_j, sim_val))\n",
    "        \n",
    "        if not scores_sims:\n",
    "            return self.trainset.global_mean\n",
    "\n",
    "        # Sort descending\n",
    "        scores_sims.sort(key=lambda x: x[1], reverse=True)\n",
    "        top_k = scores_sims[: self.k]\n",
    "        \n",
    "        numerator = sum(rating_j * sim_j for (rating_j, sim_j) in top_k)\n",
    "        denominator = sum(sim_j for (_, sim_j) in top_k)\n",
    "        \n",
    "        if denominator == 0:\n",
    "            return self.trainset.global_mean\n",
    "        return numerator / denominator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "93d4fad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.8999\n",
      "Embedding-Based RMSE: 0.8998568097578655\n"
     ]
    }
   ],
   "source": [
    "# Train & Evaluate\n",
    "\n",
    "algo = EmbeddingBased(book_embeddings=book_embeddings, k=10)\n",
    "algo.fit(trainset)\n",
    "predictions = algo.test(testset)\n",
    "rmse = accuracy.rmse(predictions)\n",
    "print(\"Embedding-Based RMSE:\", rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c749c6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_recall(predictions, k=10, threshold=3.5):\n",
    "    \"\"\"\n",
    "    Evaluate precision and recall at k, given a list of predictions:\n",
    "      predictions is a list of tuples (uid, iid, true_r, est, details),\n",
    "      k is the number of top items to consider,\n",
    "      threshold is the rating threshold above which a user is said to have 'liked' the item.\n",
    "      \n",
    "    Returns: (mean_precision, mean_recall)\n",
    "    \"\"\"\n",
    "    # Map each user to a list of (estimated rating, true rating)\n",
    "    user_est_true = defaultdict(list)\n",
    "    for uid, iid, true_r, est, _ in predictions:\n",
    "        user_est_true[uid].append((iid, est, true_r))\n",
    "    \n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    \n",
    "    for uid, user_ratings in user_est_true.items():\n",
    "        # Sort user_ratings by predicted rating 'est' descending\n",
    "        user_ratings.sort(key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        # Number of relevant items (true rating >= threshold)\n",
    "        n_rel = sum((true_r >= threshold) for (_, _, true_r) in user_ratings)\n",
    "        \n",
    "        # Number of recommended items in top k that are relevant\n",
    "        n_rec_k = sum((true_r >= threshold) for (_, _, true_r) in user_ratings[:k])\n",
    "        \n",
    "        # Precision@k: Proportion of recommended items in top k that are relevant\n",
    "        if k > 0:\n",
    "            precision = n_rec_k / k\n",
    "        else:\n",
    "            precision = 1\n",
    "        \n",
    "        # Recall@k: Proportion of relevant items found in top k\n",
    "        if n_rel != 0:\n",
    "            recall = n_rec_k / n_rel\n",
    "        else:\n",
    "            recall = 1\n",
    "        \n",
    "        precisions.append(precision)\n",
    "        recalls.append(recall)\n",
    "    \n",
    "    mean_precision = np.mean(precisions)\n",
    "    mean_recall = np.mean(recalls)\n",
    "    \n",
    "    return mean_precision, mean_recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a8539dcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.8999\n",
      "Precision@10: 0.9000\n",
      "Recall@10:    0.0060\n"
     ]
    }
   ],
   "source": [
    "algo = EmbeddingBased(book_embeddings=book_embeddings, k=10)\n",
    "algo.fit(trainset)\n",
    "\n",
    "# Generate predictions on the test set\n",
    "predictions = algo.test(testset)\n",
    "\n",
    "# Evaluate RMSE (optional)\n",
    "rmse = accuracy.rmse(predictions)\n",
    "\n",
    "# Evaluate precision & recall\n",
    "p, r = precision_recall(predictions, k=10, threshold=3.5)\n",
    "print(f\"Precision@10: {p:.4f}\")\n",
    "print(f\"Recall@10:    {r:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f4643bc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.8979\n",
      "======== Cold-Start Analysis (Embedding-Based) ========\n",
      "Overall RMSE: 0.8979, Precision: 0.9000, Recall: 0.0060\n",
      "New Item RMSE: 0.2603, Precision: 0.1000, Recall: 1.0000\n",
      "Old Items RMSE: 0.8982, Precision: 0.9000, Recall: 0.0060\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from surprise import Dataset, Reader, accuracy\n",
    "from surprise.model_selection import train_test_split\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from surprise import AlgoBase\n",
    "from collections import defaultdict\n",
    "\n",
    "####################################\n",
    "# 1) PREPARE THE DATA\n",
    "####################################\n",
    "\n",
    "book_df = pd.read_csv('Amazon_Books_Scraping/Books_df.csv')\n",
    "\n",
    "# Ensure we have a 'book_id' column\n",
    "if 'book_id' not in book_df.columns:\n",
    "    book_df.insert(0, 'book_id', range(len(book_df)))\n",
    "\n",
    "# Create a simple text representation for each book (for embeddings)\n",
    "def create_metadata_text(row):\n",
    "    return (\n",
    "        f\"Title: {row['Title']} | \"\n",
    "        f\"Author: {row['Author']} | \"\n",
    "        f\"Main Genre: {row['Main Genre']} | \"\n",
    "        f\"Sub Genre: {row['Sub Genre']}\"\n",
    "    )\n",
    "\n",
    "book_df['text_for_embedding'] = book_df.apply(create_metadata_text, axis=1)\n",
    "\n",
    "# We'll create a user-item rating DataFrame for Surprise\n",
    "# Note: This is still \"faking\" user input. We'll just treat 'user_id=0' for demonstration.\n",
    "# If you have real user IDs, replace this logic.\n",
    "ratings_df = pd.DataFrame({\n",
    "    'user_id': 0,  # single user scenario (fake)\n",
    "    'item_id': book_df['book_id'],\n",
    "    'rating': book_df['Rating'].astype(float)\n",
    "})\n",
    "\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "full_data = Dataset.load_from_df(ratings_df[['user_id', 'item_id', 'rating']], reader)\n",
    "\n",
    "# Split into train/test\n",
    "trainset_cold, testset_cold = train_test_split(full_data, test_size=0.2, random_state=21)\n",
    "test_df_cold = pd.DataFrame(testset_cold, columns=['user_id', 'item_id', 'rating'])\n",
    "\n",
    "####################################\n",
    "# 2) INTRODUCE A COLD-START ITEM\n",
    "####################################\n",
    "\n",
    "# We'll add a brand new item that does NOT appear in the training set.\n",
    "# For example, item_id=9999 with \"Action & Adventure\" rating=4.\n",
    "# (If you want it to be a brand-new user, you'd change 'user_id' instead.)\n",
    "cold_item_id = 9999\n",
    "new_item = [(0, cold_item_id, 4.0)]  \n",
    "# user_id=0 (since we only have user=0)\n",
    "# item_id=9999 doesn't exist in training. rating=4.0 is arbitrary for demonstration.\n",
    "\n",
    "new_item_df = pd.DataFrame(new_item, columns=['user_id', 'item_id', 'rating'])\n",
    "test_df_cold = pd.concat([test_df_cold, new_item_df], ignore_index=True)\n",
    "\n",
    "# Convert test_df_cold back into a Surprise testset format: list of (user, item, rating) tuples\n",
    "testset_new = list(test_df_cold[['user_id', 'item_id', 'rating']].itertuples(index=False, name=None))\n",
    "\n",
    "####################################\n",
    "# 3) CREATE EMBEDDINGS\n",
    "####################################\n",
    "\n",
    "# We'll use a SentenceTransformer model to embed each book's metadata.\n",
    "# This is done only for the books that appear in the TRAINING set\n",
    "# (which is the normal scenario: new items won't have embeddings unless you embed them).\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Build a dict: book_id -> embedding for all books that appear in the TRAINING set\n",
    "train_items = trainset_cold.build_testset()  # all (user, item, rating) in train\n",
    "train_item_ids = {iid for (_, iid, _) in train_items}\n",
    "\n",
    "train_book_df = book_df[book_df['book_id'].isin(train_item_ids)].copy()\n",
    "train_book_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# 2) Encode the text\n",
    "train_embeddings_tensor = model.encode(\n",
    "    train_book_df['text_for_embedding'].tolist(), \n",
    "    convert_to_tensor=True\n",
    ")\n",
    "\n",
    "# 3) Now iterate using the rowâ€™s *new* index\n",
    "for idx, row in train_book_df.iterrows():\n",
    "    b_id = row['book_id']\n",
    "    book_embeddings[b_id] = train_embeddings_tensor[idx]\n",
    "\n",
    "# NOTE: We have NOT embedded item_id=9999 because it's truly \"cold\" (no metadata).\n",
    "# If you *did* have metadata, you could embed it here. That wouldn't be a total cold start anymore.\n",
    "# We'll show how to handle that scenario below.\n",
    "\n",
    "\n",
    "####################################\n",
    "# 4) CUSTOM EMBEDDING-BASED ALGORITHM\n",
    "####################################\n",
    "\n",
    "class EmbeddingBased(AlgoBase):\n",
    "    def __init__(self, book_embeddings, k=10):\n",
    "        AlgoBase.__init__(self)\n",
    "        self.book_embeddings = book_embeddings  # dict: item_id -> embedding\n",
    "        self.k = k\n",
    "    \n",
    "    def fit(self, trainset):\n",
    "        AlgoBase.fit(self, trainset)\n",
    "        return self\n",
    "    \n",
    "    def estimate(self, u, i):\n",
    "        # Convert internal IDs to raw IDs\n",
    "        try:\n",
    "            user_id = self.trainset.to_raw_uid(u)\n",
    "        except ValueError:\n",
    "            return self.trainset.global_mean\n",
    "        \n",
    "        try:\n",
    "            item_id = self.trainset.to_raw_iid(i)\n",
    "        except ValueError:\n",
    "            return self.trainset.global_mean\n",
    "        \n",
    "        # If this item is not in our embeddings dictionary => cold start item\n",
    "        if item_id not in self.book_embeddings:\n",
    "            # fallback to global mean (or any other strategy)\n",
    "            return self.trainset.global_mean\n",
    "        \n",
    "        # Get all items that user has rated in training\n",
    "        user_ratings = self.trainset.ur[u]  # list of (inner_item_id, rating)\n",
    "        if len(user_ratings) == 0:\n",
    "            # user never rated anything => fallback\n",
    "            return self.trainset.global_mean\n",
    "        \n",
    "        target_emb = self.book_embeddings[item_id]\n",
    "        scores_sims = []\n",
    "        \n",
    "        # We'll use sentence_transformers.util.cos_sim for similarity\n",
    "        for (j_inner, rating_j) in user_ratings:\n",
    "            j_raw = self.trainset.to_raw_iid(j_inner)\n",
    "            # If the user-rated item is in the embedding dictionary\n",
    "            if j_raw in self.book_embeddings:\n",
    "                j_emb = self.book_embeddings[j_raw]\n",
    "                sim_val = float(util.cos_sim(target_emb, j_emb)[0][0])\n",
    "                scores_sims.append((rating_j, sim_val))\n",
    "        \n",
    "        if not scores_sims:\n",
    "            return self.trainset.global_mean\n",
    "        \n",
    "        # Sort descending by similarity\n",
    "        scores_sims.sort(key=lambda x: x[1], reverse=True)\n",
    "        top_k = scores_sims[:self.k]\n",
    "        \n",
    "        numerator = sum(r * s for (r, s) in top_k)\n",
    "        denominator = sum(s for (_, s) in top_k)\n",
    "        \n",
    "        if denominator == 0:\n",
    "            return self.trainset.global_mean\n",
    "        return numerator / denominator\n",
    "\n",
    "####################################\n",
    "# 5) TRAIN & TEST\n",
    "####################################\n",
    "\n",
    "algo_cold = EmbeddingBased(book_embeddings=book_embeddings, k=10)\n",
    "algo_cold.fit(trainset_cold)\n",
    "\n",
    "pred_knn_cold = algo_cold.test(testset_new)\n",
    "rmse_knn_cold = accuracy.rmse(pred_knn_cold, verbose=True)\n",
    "\n",
    "####################################\n",
    "# 6) SPLIT NEW ITEM vs OLD ITEMS\n",
    "####################################\n",
    "\n",
    "# Our \"cold item\" is item_id = 9999\n",
    "cold_item_ids = {9999}\n",
    "\n",
    "preds_new = [p for p in pred_knn_cold if p.iid in cold_item_ids]\n",
    "preds_old = [p for p in pred_knn_cold if p.iid not in cold_item_ids]\n",
    "\n",
    "# Evaluate separate RMSE\n",
    "rmse_new = accuracy.rmse(preds_new, verbose=False)\n",
    "rmse_old = accuracy.rmse(preds_old, verbose=False)\n",
    "\n",
    "####################################\n",
    "# 7) PRECISION/RECALL FUNCTION\n",
    "####################################\n",
    "def precision_recall(predictions, k=10, threshold=3.5):\n",
    "    from collections import defaultdict\n",
    "    user_est_true = defaultdict(list)\n",
    "    for uid, iid, true_r, est, _ in predictions:\n",
    "        user_est_true[uid].append((iid, est, true_r))\n",
    "    \n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    \n",
    "    for uid, user_ratings in user_est_true.items():\n",
    "        # Sort by estimated rating descending\n",
    "        user_ratings.sort(key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        # number of relevant items\n",
    "        n_rel = sum((true_r >= threshold) for (_, _, true_r) in user_ratings)\n",
    "        \n",
    "        # number of recommended items in top k that are relevant\n",
    "        n_rec_k = sum((true_r >= threshold) for (_, _, true_r) in user_ratings[:k])\n",
    "        \n",
    "        precision = n_rec_k / k if k > 0 else 1\n",
    "        recall = n_rec_k / n_rel if n_rel != 0 else 1\n",
    "        \n",
    "        precisions.append(precision)\n",
    "        recalls.append(recall)\n",
    "    \n",
    "    mean_precision = np.mean(precisions)\n",
    "    mean_recall = np.mean(recalls)\n",
    "    return mean_precision, mean_recall\n",
    "\n",
    "p_all_cold, r_all_cold = precision_recall(pred_knn_cold, k=10, threshold=3.5)\n",
    "p_new, r_new = precision_recall(preds_new, k=10, threshold=3.5)\n",
    "p_old, r_old = precision_recall(preds_old, k=10, threshold=3.5)\n",
    "\n",
    "####################################\n",
    "# 8) REPORT RESULTS\n",
    "####################################\n",
    "print(\"======== Cold-Start Analysis (Embedding-Based) ========\")\n",
    "print(f\"Overall RMSE: {rmse_knn_cold:.4f}, Precision: {p_all_cold:.4f}, Recall: {r_all_cold:.4f}\")\n",
    "print(f\"New Item RMSE: {rmse_new:.4f}, Precision: {p_new:.4f}, Recall: {r_new:.4f}\")\n",
    "print(f\"Old Items RMSE: {rmse_old:.4f}, Precision: {p_old:.4f}, Recall: {r_old:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9fee31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 7928 books from CSV.\n",
      "Created embeddings for each book.\n",
      "Synthetic Ratings: 237736 total ratings from 50 users.\n",
      "Train/Test Split Done.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from surprise import Dataset, Reader\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise import accuracy\n",
    "from surprise import AlgoBase\n",
    "from collections import defaultdict\n",
    "\n",
    "###########################################################\n",
    "# 1) LOAD THE REAL BOOK DATA (from CSV)\n",
    "###########################################################\n",
    "\n",
    "df_books = pd.read_csv(\"Amazon_Books_Scraping/Books_df.csv\")\n",
    "\n",
    "# Ensure there's a 'book_id' column\n",
    "if 'book_id' not in df_books.columns:\n",
    "    df_books.insert(0, 'book_id', range(len(df_books)))\n",
    "\n",
    "# We'll create a text column for embeddings\n",
    "def create_metadata_text(row):\n",
    "    return (\n",
    "        f\"Title: {row['Title']} | \"\n",
    "        f\"Author: {row['Author']} | \"\n",
    "        f\"Main Genre: {row['Main Genre']} | \"\n",
    "        f\"Sub Genre: {row['Sub Genre']}\"\n",
    "    )\n",
    "df_books['text_for_embedding'] = df_books.apply(create_metadata_text, axis=1)\n",
    "\n",
    "# (Optional) You can drop any rows with missing or invalid data\n",
    "# df_books.dropna(subset=[\"Title\", \"Author\", \"Main Genre\", \"Sub Genre\"], inplace=True)\n",
    "\n",
    "print(f\"Loaded {len(df_books)} books from CSV.\")\n",
    "\n",
    "###########################################################\n",
    "# 2) CREATE EMBEDDINGS FOR EACH BOOK\n",
    "###########################################################\n",
    "\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "texts = df_books[\"text_for_embedding\"].tolist()\n",
    "embeddings_tensor = model.encode(texts, convert_to_tensor=True)\n",
    "\n",
    "book_embeddings = {}\n",
    "for idx, row in df_books.iterrows():\n",
    "    b_id = row['book_id']\n",
    "    book_embeddings[b_id] = embeddings_tensor[idx]\n",
    "\n",
    "print(\"Created embeddings for each book.\")\n",
    "\n",
    "###########################################################\n",
    "# 3) SYNTHETICALLY GENERATE 50 USERS' RATINGS\n",
    "###########################################################\n",
    "\n",
    "num_users = 50\n",
    "prob_rate = 0.6  # each user has a 60% chance to rate any given book\n",
    "\n",
    "ratings_data = []\n",
    "np.random.seed(42)  # for reproducibility\n",
    "\n",
    "# We'll gather all the book_ids in a list\n",
    "all_book_ids = df_books['book_id'].tolist()\n",
    "\n",
    "for user_id in range(num_users):\n",
    "    for book_id in all_book_ids:\n",
    "        # Decide if this user rates this book\n",
    "        if np.random.rand() < prob_rate:\n",
    "            # random rating from 1..5\n",
    "            rating_val = np.random.randint(1, 6)  # 1 to 5\n",
    "            ratings_data.append((user_id, book_id, rating_val))\n",
    "\n",
    "df_ratings = pd.DataFrame(ratings_data, columns=[\"user_id\", \"book_id\", \"rating\"])\n",
    "print(f\"Synthetic Ratings: {df_ratings.shape[0]} total ratings from {num_users} users.\")\n",
    "\n",
    "###########################################################\n",
    "# 4) CREATE A SURPRISE DATASET\n",
    "###########################################################\n",
    "\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "data = Dataset.load_from_df(df_ratings[[\"user_id\", \"book_id\", \"rating\"]], reader)\n",
    "\n",
    "trainset, testset = train_test_split(data, test_size=0.2, random_state=42)\n",
    "print(\"Train/Test Split Done.\")\n",
    "\n",
    "###########################################################\n",
    "# 5) DEFINE A CUSTOM EMBEDDING-BASED ALGO\n",
    "###########################################################\n",
    "\n",
    "class EmbeddingBased(AlgoBase):\n",
    "    def __init__(self, book_embeddings, k=10):\n",
    "        AlgoBase.__init__(self)\n",
    "        self.book_embeddings = book_embeddings\n",
    "        self.k = k\n",
    "    \n",
    "    def fit(self, trainset):\n",
    "        super().fit(trainset)\n",
    "        return self\n",
    "    \n",
    "    def estimate(self, u, i):\n",
    "        from sentence_transformers import util\n",
    "        # Convert internal IDs to raw IDs\n",
    "        try:\n",
    "            user_id = self.trainset.to_raw_uid(u)\n",
    "        except ValueError:\n",
    "            return self.trainset.global_mean\n",
    "        \n",
    "        try:\n",
    "            book_id = self.trainset.to_raw_iid(i)\n",
    "        except ValueError:\n",
    "            return self.trainset.global_mean\n",
    "        \n",
    "        # If no embedding for this book => cold start fallback\n",
    "        if book_id not in self.book_embeddings:\n",
    "            return self.trainset.global_mean\n",
    "        \n",
    "        # Gather user's rated items\n",
    "        user_ratings = self.trainset.ur[u]  # list of (inner_item_id, rating)\n",
    "        if not user_ratings:\n",
    "            return self.trainset.global_mean\n",
    "        \n",
    "        target_emb = self.book_embeddings[book_id]\n",
    "        \n",
    "        scores_sims = []\n",
    "        for (j_inner, rating_j) in user_ratings:\n",
    "            j_raw = self.trainset.to_raw_iid(j_inner)\n",
    "            if j_raw in self.book_embeddings:\n",
    "                j_emb = self.book_embeddings[j_raw]\n",
    "                sim_val = float(util.cos_sim(target_emb, j_emb)[0][0])\n",
    "                scores_sims.append((rating_j, sim_val))\n",
    "        \n",
    "        if not scores_sims:\n",
    "            return self.trainset.global_mean\n",
    "        \n",
    "        # Sort by similarity descending\n",
    "        scores_sims.sort(key=lambda x: x[1], reverse=True)\n",
    "        top_k = scores_sims[: self.k]\n",
    "        \n",
    "        numerator = sum(r * s for (r, s) in top_k)\n",
    "        denominator = sum(s for (_, s) in top_k)\n",
    "        \n",
    "        if denominator == 0:\n",
    "            return self.trainset.global_mean\n",
    "        return numerator / denominator\n",
    "\n",
    "###########################################################\n",
    "# 6) TRAIN & EVALUATE THE EMBEDDING-BASED MODEL\n",
    "###########################################################\n",
    "\n",
    "algo_llm = EmbeddingBased(book_embeddings, k=10)\n",
    "algo_llm.fit(trainset)\n",
    "predictions_llm = algo_llm.test(testset)\n",
    "rmse_llm = accuracy.rmse(predictions_llm, verbose=True)\n",
    "\n",
    "###########################################################\n",
    "# 7) PRECISION/RECALL EVALUATION\n",
    "###########################################################\n",
    "def precision_recall(predictions, k=10, threshold=3.5):\n",
    "    user_est_true = defaultdict(list)\n",
    "    for uid, iid, true_r, est, _ in predictions:\n",
    "        user_est_true[uid].append((iid, est, true_r))\n",
    "    \n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    \n",
    "    for uid, user_ratings in user_est_true.items():\n",
    "        # Sort by estimated rating descending\n",
    "        user_ratings.sort(key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        # number of relevant items\n",
    "        n_rel = sum((true_r >= threshold) for (_, _, true_r) in user_ratings)\n",
    "        \n",
    "        # number of recommended items in top k that are relevant\n",
    "        n_rec_k = sum((true_r >= threshold) for (_, _, true_r) in user_ratings[:k])\n",
    "        \n",
    "        precision = n_rec_k / k if k > 0 else 1\n",
    "        recall = n_rec_k / n_rel if n_rel != 0 else 1\n",
    "        \n",
    "        precisions.append(precision)\n",
    "        recalls.append(recall)\n",
    "    \n",
    "    mean_precision = np.mean(precisions)\n",
    "    mean_recall = np.mean(recalls)\n",
    "    return mean_precision, mean_recall\n",
    "\n",
    "p_llm, r_llm = precision_recall(predictions_llm, k=10, threshold=3.5)\n",
    "print(f\"\\nPrecision@10: {p_llm:.4f}, Recall@10: {r_llm:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
